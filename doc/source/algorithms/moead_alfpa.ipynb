{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. _nb_moead:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOEA/D_ALFPA\n",
    "\n",
    "\n",
    "This algorithm is implemented based on <cite data-cite=\"moead\"></cite>. The algorithm is based on [Reference Directions](../misc/reference_directions.ipynb) which need to be provided when initializing the algorithm object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from pymoo.algorithms.so_cuckoo_search import MantegnasAlgorithm\n",
    "from pymoo.decomposition.pbi import PBI\n",
    "from pymoo.docs import parse_doc_string\n",
    "from pymoo.model.algorithm import Algorithm\n",
    "from pymoo.model.duplicate import DefaultDuplicateElimination\n",
    "from pymoo.model.initialization import Initialization\n",
    "from pymoo.model.population import Population\n",
    "from pymoo.operators.repair.to_bound import set_to_bounds_if_outside\n",
    "from pymoo.operators.sampling.random_sampling import FloatRandomSampling\n",
    "from pymoo.util.termination.default import MultiObjectiveDefaultTermination\n",
    "from pymoo.util.misc import has_feasible\n",
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "\n",
    "class AdaptiveLevyFlight:\n",
    "    def __init__(self, alpha, beta, do_all=True):\n",
    "        self.alpha = alpha\n",
    "        #beta must be in range of [1..2]\n",
    "        beta = min(beta, 2)\n",
    "        beta = max(beta, 1)\n",
    "        self.beta = beta            \n",
    "        self.cauchy = np.random.default_rng().standard_cauchy\n",
    "        self.gaussian = np.random.default_rng().standard_normal        \n",
    "        self.do_all = do_all\n",
    "        if do_all:\n",
    "            self.levy1 = MantegnasAlgorithm(1.3) \n",
    "            self.levy2 = MantegnasAlgorithm(1.7)\n",
    "        else:\n",
    "            self.levy = MantegnasAlgorithm(beta)        \n",
    "\n",
    "    def _do_all(self, xbest, xi, xl, xu):\n",
    "        cstep = self.cauchy(len(xi))\n",
    "        lstep1 = self.levy1.do(len(xi))\n",
    "        lstep2 = self.levy2.do(len(xi))\n",
    "        gstep = self.gaussian(len(xi))\n",
    "        steps = np.array([cstep, lstep1, lstep2, gstep])\n",
    "        direction = xbest-xi\n",
    "        scale = xu-xl\n",
    "        _X = xi + direction*scale*steps\n",
    "        _X = set_to_bounds_if_outside(_X, xl, xu)\n",
    "        return Population.new(X=_X)\n",
    "    \n",
    "    def _do(self, xbest, xi, xl, xu):\n",
    "        \n",
    "        if self.do_all:\n",
    "            return self._do_all(xbest, xi, xl, xu)\n",
    "        \n",
    "        # get random levy values to be used for the step size\n",
    "        if self.beta == 1:\n",
    "            levy = self.cauchy(len(xi))\n",
    "        elif self.beta == 2:\n",
    "            levy = self.gaussian(len(xi))\n",
    "        else:\n",
    "            levy = self.levy.do(len(xi))\n",
    "        direction = (xbest-xi)\n",
    "        _x = xi + (xu - xl)*self.alpha * levy * direction\n",
    "        _x = set_to_bounds_if_outside(_x, xl, xu)\n",
    "\n",
    "        return Population.new(X=_x[None, :])    \n",
    "    \n",
    "    \n",
    "def calc_harmonic_average_distance(points, neighbors=None):\n",
    "    dist_mat = []\n",
    "    K = len(points)\n",
    "    if neighbors is None:\n",
    "        #had among themselves        \n",
    "        dist_mat = cdist(points, points)\n",
    "        np.fill_diagonal(dist_mat, np.inf)\n",
    "        K = len(points) - 1\n",
    "    else:\n",
    "        dist_mat  = cdist(points, neighbors)\n",
    "        K = len(neighbors)\n",
    "        \n",
    "    dist_mat_inv = 1/dist_mat\n",
    "    had = K/np.sum(dist_mat_inv, axis=1)\n",
    "    return had    \n",
    "\n",
    "class MOEAD_ALFPA(Algorithm):\n",
    "\n",
    "    def __init__(self,\n",
    "                 ref_dirs,\n",
    "                 sampling=FloatRandomSampling(),\n",
    "                 eliminate_duplicates=DefaultDuplicateElimination(),\n",
    "                 termination=MultiObjectiveDefaultTermination(),\n",
    "                 decomposition=PBI(),\n",
    "                 adaptive=False,\n",
    "                 archive_size=100,\n",
    "                 n_neighbors=None,\n",
    "                 n_replacement=3,                 \n",
    "                 alpha=0.01,\n",
    "                 p=0.8,\n",
    "                 pa=0.8,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        display : {display}\n",
    "        sampling : {sampling}\n",
    "        survival : {survival}\n",
    "        eliminate_duplicates: This does not exists in the original paper/book.\n",
    "            Without this the solutions might get too biased to current global best solution,\n",
    "            because the global random walk use the global best solution as the reference.\n",
    "\n",
    "        termination : {termination}\n",
    "\n",
    "        pop_size : The number of nests (solutions)\n",
    "\n",
    "        beta : The input parameter of the Mantegna's Algorithm to simulate\n",
    "            sampling on Levy Distribution\n",
    "\n",
    "        alfa : alfa is the step size scaling factor and is usually\n",
    "            0.01, so that the step size will be scaled down to O(L/100) with L is\n",
    "            the scale (range of bounds) of the problem.\n",
    "\n",
    "        pa   : The switch probability\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        #prepare operators\n",
    "        self.adaptive = adaptive\n",
    "        if not adaptive:\n",
    "            self.grw = AdaptiveLevyFlight(alpha, 0, do_all=True)\n",
    "        else:\n",
    "            cauchy = AdaptiveLevyFlight(alpha, 1, do_all=False)\n",
    "            levy1 = AdaptiveLevyFlight(alpha, 1.3, do_all=False)\n",
    "            levy2 = AdaptiveLevyFlight(alpha, 1.7, do_all=False)\n",
    "            gaussian = AdaptiveLevyFlight(alpha, 2, do_all=False)\n",
    "            self.mating = [cauchy, levy1, levy2, gaussian]\n",
    "\n",
    "        self.initialization = Initialization(sampling)        \n",
    "        self.default_termination = termination\n",
    "        self.eliminate_duplicates = eliminate_duplicates\n",
    "        self.decomposition = decomposition\n",
    "        self.nds = NonDominatedSorting()  \n",
    "        \n",
    "        self.archive_size = archive_size\n",
    "        self.ref_dirs = ref_dirs\n",
    "        self.pop_size = len(ref_dirs)\n",
    "        #prepare neighbours list\n",
    "        #neighbours includes the entry by itself intentionally for the survival method\n",
    "        self.n_neighbors = n_neighbors\n",
    "        if n_neighbors is None:\n",
    "            self.n_neighbors = int(0.1*self.pop_size)\n",
    "        self.neighbors_list = np.argsort(cdist(self.ref_dirs, self.ref_dirs), axis=1, kind='quicksort')\n",
    "        self.neighbors_list = self.neighbors_list[:, :self.n_neighbors]\n",
    "                \n",
    "        #the scale will be multiplied by problem scale after problem given in setup                \n",
    "        self.alpha = alpha\n",
    "        self.p = p\n",
    "        self.pa = pa\n",
    "        self.n_replacement = n_replacement          \n",
    "        \n",
    "        #parameters for adaptive operators\n",
    "        self.c = 5\n",
    "        self.W = int(self.pop_size/2)\n",
    "        self.used_op = np.full(self.W, -1)\n",
    "        self.op_rewards = np.full(self.W, 0)\n",
    "        self.sw_idx = 0\n",
    "       \n",
    "        #prepare external archive\n",
    "        self.ideal_point = []        \n",
    "        \n",
    "        \n",
    "    def _initialize(self):\n",
    "        pop = self.initialization.do(self.problem,\n",
    "                                     self.pop_size,\n",
    "                                     algorithm=self,\n",
    "                                     eliminate_duplicates=self.eliminate_duplicates)\n",
    "        self.evaluator.eval(self.problem, pop, algorithm=self)\n",
    "        self.pop = pop\n",
    "        self.opt = pop\n",
    "        F = self.pop.get(\"F\")\n",
    "        self.ideal_point = np.min(F, axis=0)\n",
    "        self.nadir_point = np.max(F, axis=0)\n",
    "\n",
    "    def _set_optimum(self, **kwargs):\n",
    "        self.opt = self.pop\n",
    "        \n",
    "    def _lrw(self, X, xi, xl, xu, n_offsprings):\n",
    "        #find n_offsprings*2 different solutions (n_offsprings pair) \n",
    "        Pair = np.random.permutation(X)[:2*n_offsprings]\n",
    "        R1, R2 = Pair[:n_offsprings], Pair[n_offsprings:2*n_offsprings]\n",
    "        r = np.tile(np.random.rand(n_offsprings), (self.problem.n_var, 1)).T\n",
    "        _X = xi + r*(R1-R2)\n",
    "        _X = set_to_bounds_if_outside(_X, xl, xu)\n",
    "        return Population.new(X=_X)\n",
    "    \n",
    "    #operator index : 0->Global Random Walk 1->Local Random Walk\n",
    "    def _calc_op_score(self, FRR, op_freq):\n",
    "        op_freq_ratio = self.c + np.sqrt(2*np.log(np.sum(op_freq))/op_freq)\n",
    "        score = FRR + op_freq_ratio\n",
    "        return score\n",
    "\n",
    "    def _choose_op(self):\n",
    "        I_op = [self.used_op == 0, self.used_op == 1]\n",
    "        op_freq = np.array([len(self.used_op[I_op[0]]), len(self.used_op[I_op[1]])])\n",
    "        #if there is an unused operator then randomly pick from the two\n",
    "        if op_freq[0]==0 or op_freq[1]==0:\n",
    "            return np.random.randint(2)\n",
    "        reward0 = np.sum(self.op_rewards[I_op[0]])\n",
    "        reward1 = np.sum(self.op_rewards[I_op[1]])\n",
    "        tot_rewards = np.sum(self.op_rewards)\n",
    "        FRR = np.array([reward0, reward1])\n",
    "        op_score = self._calc_op_score(FRR, op_freq)\n",
    "        return np.argmin(op_score)\n",
    "        \n",
    "    def _next(self):\n",
    "        xl, xu = self.problem.bounds()\n",
    "        pop_idx_permutation = np.random.permutation(self.pop_size)\n",
    "        X = self.pop.get(\"X\")\n",
    "        F = self.pop.get(\"F\")\n",
    "        Xopt = self.opt.get(\"X\")\n",
    "        for idx in pop_idx_permutation:                        \n",
    "            xi = X[idx]            \n",
    "            #choose current neighbourhood wether from ref neighbors or from all population\n",
    "            #N = neighborhood\n",
    "            if np.random.rand() < self.p:\n",
    "                N = self.neighbors_list[idx]\n",
    "            else:\n",
    "                N = np.arange(self.pop_size)        \n",
    "            \n",
    "            #permute the N so that they have fair chance to be updated (because)\n",
    "            #the number of improvement is limited\n",
    "            N = np.random.permutation(N)\n",
    "            \n",
    "            #choose operator\n",
    "            \n",
    "                        \n",
    "            #evaluate and update ideal value\n",
    "            self.evaluator.eval(self.problem, off)\n",
    "            _F = off.get(\"F\")\n",
    "            _X = off.get(\"X\")\n",
    "            self.ideal_point = np.min(np.vstack([self.ideal_point, _F]), axis=0)\n",
    "\n",
    "            # calculate the decomposed values for each neighbor\n",
    "            rho = self.alpha**self.problem.n_var\n",
    "            FV = self.decomposition.do(F[N], weights=self.ref_dirs[N, :], ideal_point=self.ideal_point, rho=rho)\n",
    "            off_FV = self.decomposition.do(_F, weights=self.ref_dirs[N, :], ideal_point=self.ideal_point, rho=rho)\n",
    "#             print(\"--------------------------------\")\n",
    "#             print(_F)\n",
    "#             print(FV, off_FV)\n",
    "#             print(self.ref_dirs[N, :])\n",
    "#             #get the best candidate of offspring for each ref_dirs\n",
    "#             off_FV_idx = np.argmin(off_FV, axis=0)\n",
    "#             off_FV = np.min(off_FV, axis=0)\n",
    "            \n",
    "            #update some of the neighbours, if the new solution is better\n",
    "            #limited to number of replacement n_replacement\n",
    "            idx = np.arange(len(N))\n",
    "            improved = off_FV < FV                        \n",
    "            idx = idx[improved][:self.n_replacement]\n",
    "            X[idx] = _X\n",
    "            F[idx] = _F\n",
    "        \n",
    "        #loop ends\n",
    "        #not \"get\"ting too many times in the loop because it's costly\n",
    "        self.pop.set(\"X\", X)\n",
    "        self.pop.set(\"F\", F)\n",
    "#         print(self.n_gen)\n",
    "\n",
    "parse_doc_string(MOEAD_ALFPA.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code": "algorithms/usage_moead.py"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Gemilang/pmop/pymoo/pymoo/operators/mutation/polynomial_mutation.py:52: RuntimeWarning: invalid value encountered in power\n",
      "  d = 1.0 - (np.power(val, mut_pow))\n",
      "/mnt/c/Users/Gemilang/pmop/pymoo/pymoo/operators/mutation/polynomial_mutation.py:47: RuntimeWarning: invalid value encountered in power\n",
      "  d = np.power(val, mut_pow) - 1.0\n",
      "/mnt/c/Users/Gemilang/pmop/pymoo/pymoo/decomposition/tchebicheff.py:27: RuntimeWarning: invalid value encountered in multiply\n",
      "  v = anp.abs(F - self.utopian_point) * weights\n",
      "/mnt/c/Users/Gemilang/pmop/pymoo/pymoo/algorithms/moead_alfpa_b.py:118: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return len(arr)/np.sum(distances)\n"
     ]
    }
   ],
   "source": [
    "from pymoo.algorithms.moead_alfpa_b import MOEAD_ALFPA_B\n",
    "from pymoo.factory import get_problem, get_visualization, get_reference_directions\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "from pymoo.decomposition.perp_dist import PerpendicularDistance\n",
    "from pymoo.decomposition.tchebicheff import Tchebicheff\n",
    "\n",
    "problem = get_problem(\"zdt6\", n_var=30)\n",
    "n_obj = 2\n",
    "ref_generating_method = \"das-dennis\"\n",
    "ref_dirs = get_reference_directions(ref_generating_method, n_obj, n_partitions=99)\n",
    "\n",
    "algorithm = MOEAD_ALFPA_B(ref_dirs=ref_dirs)\n",
    "res = minimize(problem, algorithm, seed=1, termination=('n_eval', 25000))\n",
    "print(res.exec_time)\n",
    "if n_obj == 2:\n",
    "    plot = Scatter()\n",
    "    plot.add(problem.pareto_front(), plot_type=\"line\", color=\"black\", alpha=0.7)\n",
    "    plot.add(res.F, color=\"red\")\n",
    "    plot.show()\n",
    "else:\n",
    "    plot = Scatter().add(res.F)\n",
    "    plot.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.33016614 0.71752184 0.60951716 0.46763846]\n",
      " [0.33016614 0.         1.01883391 0.89069313 0.59074692]\n",
      " [0.71752184 1.01883391 0.         0.15745609 0.60658613]\n",
      " [0.60951716 0.89069313 0.15745609 0.         0.44921774]\n",
      " [0.46763846 0.59074692 0.60658613 0.44921774 0.        ]]\n",
      "[0.42496872 0.56608802 0.5000796  0.42137682 0.42283785]\n",
      "[0.48771501 0.58601311 0.38555155 0.35272022 0.5190869 ]\n",
      "[[0.85694451 0.46354503]\n",
      " [0.9934536  0.16292076]\n",
      " [0.28032778 0.89057047]\n",
      " [0.3118635  0.73630473]\n",
      " [0.41883305 0.30000885]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "A = np.random.rand(5,2)\n",
    "print(cdist(A, A))\n",
    "print(np.average(cdist(A,A), axis=1))\n",
    "print(calc_harmonic_average_distance(A))\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 1 9 3]\n",
      " [0 2 5 3]\n",
      " [5 9 5 9]]\n",
      "[1 2 9]\n"
     ]
    }
   ],
   "source": [
    "B = np.random.randint(10, size=(3,4))\n",
    "print(B)\n",
    "print(B.T[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. autoclass:: pymoo.algorithms.moead.MOEAD\n",
    "    :noindex:"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
